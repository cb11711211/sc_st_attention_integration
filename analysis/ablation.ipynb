{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuxinchao/software/miniconda3/envs/pytorch-gpu/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scanpy as sc\n",
    "import muon as mu\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import anndata as ad\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import RandomNodeSplit, RandomLinkSplit\n",
    "from torch_geometric.loader import DataLoader, NeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import Trainer\n",
    "from dataset import GeneVocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting settings\n",
    "\n",
    "colors = [\"#3B7EA1\", \"#FDB515\", \"#D9661F\", \"#859438\", \"#EE1F60\", \"#00A598\"]\n",
    "sns.set(context=\"notebook\", font_scale=1.3, style=\"ticks\")\n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['savefig.transparent'] = True\n",
    "sc.settings._vector_friendly = True\n",
    "DPI = 300\n",
    "# GPU settings\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CITE-seq SNL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data_path\n",
    "save_path = \"/home/wuxinchao/data/st_cite_data/totalVI_reproducibility/data/\"\n",
    "mdata = mu.read_h5mu(save_path + \"/SNL_111.h5mu\")\n",
    "rna = mdata.mod[\"rna\"]\n",
    "protein = mdata.mod[\"prot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AnnData object with n_obs × n_vars = 9264 × 4005\n",
       "     obs: 'n_protein_counts', 'n_proteins', 'seurat_hash_id', 'batch_indices', 'hash_id', 'n_genes', 'percent_mito', 'leiden_subclusters', 'cell_types', 'leiden_totalVI', 'combined_cell_types'\n",
       "     var: 'gene_ids', 'feature_types', 'highly_variable', 'highly_variable_mean_variance', 'encode', 'hvg_encode'\n",
       "     uns: 'cell_types_colors', 'combined_cell_types_colors', 'leiden', 'leiden_totalVI_colors', 'neighbors', 'protein_names', 'umap', 'version'\n",
       "     obsm: 'X_totalVI', 'X_umap', 'protein_expression'\n",
       "     layers: 'counts', 'denoised_rna'\n",
       "     obsp: 'connectivities', 'distances',\n",
       " AnnData object with n_obs × n_vars = 9264 × 110\n",
       "     obs: 'n_protein_counts', 'n_proteins', 'seurat_hash_id', 'batch_indices', 'hash_id', 'n_genes', 'percent_mito', 'leiden_subclusters', 'cell_types', '_scvi_batch'\n",
       "     var: 'clean_names'\n",
       "     layers: 'denoised_protein', 'protein_foreground_prob')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rna, protein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNA\n",
    "sc.pp.normalize_total(rna)\n",
    "sc.pp.log1p(rna)\n",
    "rna.obs_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from muon import prot as pt\n",
    "\n",
    "pt.pp.clr(protein)\n",
    "mdata.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2764549/2886634033.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  edge_index = torch.tensor(edge_index,\n"
     ]
    }
   ],
   "source": [
    "concat_data = np.concatenate(\n",
    "    [rna.X, protein.X], axis=1\n",
    ")\n",
    "\n",
    "adj_mtx = rna.obsp['connectivities'].toarray()\n",
    "edge_index = adj_mtx.nonzero()\n",
    "edge_index = torch.tensor(edge_index, \n",
    "        dtype=torch.long).contiguous()\n",
    "\n",
    "scCITEseq_data = Data(x=torch.tensor(\n",
    "    concat_data, dtype=torch.float), \n",
    "    edge_index=edge_index)\n",
    "\n",
    "geneVocab = GeneVocab(rna)\n",
    "proteinVocab = GeneVocab(protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 2\n",
    "num_val = 0.2\n",
    "num_test = 0.2\n",
    "\n",
    "tsf = RandomNodeSplit(num_splits=num_splits, \n",
    "                      num_val=num_val, \n",
    "                      num_test=num_test, \n",
    "                      key=None\n",
    "                      )\n",
    "training_data = tsf(scCITEseq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting for the model\n",
    "rna_input_dim = rna.shape[1]\n",
    "prot_input_dim = protein.shape[1]\n",
    "hidden_dim = 32\n",
    "embedding_dim = 32\n",
    "heads = 4\n",
    "num_blocks = 2\n",
    "permute = False\n",
    "preserve_rate = 0.2\n",
    "alpha = 0.4\n",
    "beta = 0.4\n",
    "\n",
    "# setting for the trainer\n",
    "batch_size = 256\n",
    "lr = 5e-5\n",
    "epochs = 50\n",
    "mask_ratio = 0.85\n",
    "num_splits = 2\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 train_loss: 21.46366 val_loss: 7.09633\n",
      "Epoch 2/50 train_loss: 20.43760 val_loss: 6.71513\n",
      "Epoch 3/50 train_loss: 18.93721 val_loss: 6.07844\n",
      "Epoch 4/50 train_loss: 16.84409 val_loss: 5.32738\n",
      "Epoch 5/50 train_loss: 14.59727 val_loss: 4.54053\n",
      "Epoch 6/50 train_loss: 12.57584 val_loss: 3.94231\n",
      "Epoch 7/50 train_loss: 11.00732 val_loss: 3.52841\n",
      "Epoch 8/50 train_loss: 9.87183 val_loss: 3.16644\n",
      "Epoch 9/50 train_loss: 8.99064 val_loss: 2.91790\n",
      "Epoch 10/50 train_loss: 8.27592 val_loss: 2.69729\n",
      "Epoch 11/50 train_loss: 7.66485 val_loss: 2.49915\n",
      "Epoch 12/50 train_loss: 7.16286 val_loss: 2.33356\n",
      "Epoch 13/50 train_loss: 6.68177 val_loss: 2.18289\n",
      "Epoch 14/50 train_loss: 6.28247 val_loss: 2.04852\n",
      "Epoch 15/50 train_loss: 5.94214 val_loss: 1.95897\n",
      "Epoch 16/50 train_loss: 5.63278 val_loss: 1.87486\n",
      "Epoch 17/50 train_loss: 5.40493 val_loss: 1.78595\n",
      "Epoch 18/50 train_loss: 5.19028 val_loss: 1.72692\n",
      "Epoch 19/50 train_loss: 5.01122 val_loss: 1.67483\n",
      "Epoch 20/50 train_loss: 4.87185 val_loss: 1.62662\n",
      "Epoch 21/50 train_loss: 4.76376 val_loss: 1.58520\n",
      "Epoch 22/50 train_loss: 4.66452 val_loss: 1.56727\n",
      "Epoch 23/50 train_loss: 4.57432 val_loss: 1.53161\n",
      "Epoch 24/50 train_loss: 4.49366 val_loss: 1.48780\n",
      "Epoch 25/50 train_loss: 4.42087 val_loss: 1.48633\n",
      "Epoch 26/50 train_loss: 4.35371 val_loss: 1.47461\n",
      "Epoch 27/50 train_loss: 4.28724 val_loss: 1.45058\n",
      "Epoch 28/50 train_loss: 4.23822 val_loss: 1.43232\n",
      "Epoch 29/50 train_loss: 4.18621 val_loss: 1.40259\n",
      "Epoch 30/50 train_loss: 4.14143 val_loss: 1.39540\n",
      "Epoch 31/50 train_loss: 4.08512 val_loss: 1.38208\n",
      "Epoch 32/50 train_loss: 4.05568 val_loss: 1.36798\n",
      "Epoch 33/50 train_loss: 4.01793 val_loss: 1.36328\n",
      "Epoch 34/50 train_loss: 3.96394 val_loss: 1.34187\n",
      "Epoch 35/50 train_loss: 3.94763 val_loss: 1.34869\n",
      "Epoch 36/50 train_loss: 3.90950 val_loss: 1.32754\n",
      "Epoch 37/50 train_loss: 3.87338 val_loss: 1.30937\n",
      "Epoch 38/50 train_loss: 3.85353 val_loss: 1.31624\n",
      "Epoch 39/50 train_loss: 3.83106 val_loss: 1.30285\n",
      "Epoch 40/50 train_loss: 3.79132 val_loss: 1.30082\n",
      "Epoch 41/50 train_loss: 3.76361 val_loss: 1.28775\n",
      "Epoch 42/50 train_loss: 3.73776 val_loss: 1.27373\n",
      "Epoch 43/50 train_loss: 3.72330 val_loss: 1.26788\n",
      "Epoch 44/50 train_loss: 3.68714 val_loss: 1.26557\n",
      "Epoch 45/50 train_loss: 3.67181 val_loss: 1.25976\n",
      "Epoch 46/50 train_loss: 3.64944 val_loss: 1.25243\n",
      "Epoch 47/50 train_loss: 3.62904 val_loss: 1.25955\n",
      "Epoch 48/50 train_loss: 3.61425 val_loss: 1.23960\n",
      "Epoch 49/50 train_loss: 3.59575 val_loss: 1.23411\n",
      "Epoch 50/50 train_loss: 3.57983 val_loss: 1.22117\n",
      "Epoch 1/50 train_loss: 21.20887 val_loss: 6.95471\n",
      "Epoch 2/50 train_loss: 19.69868 val_loss: 6.38150\n",
      "Epoch 3/50 train_loss: 17.74637 val_loss: 5.65782\n",
      "Epoch 4/50 train_loss: 15.58336 val_loss: 4.94233\n",
      "Epoch 5/50 train_loss: 13.57311 val_loss: 4.34495\n",
      "Epoch 6/50 train_loss: 11.99111 val_loss: 3.85734\n",
      "Epoch 7/50 train_loss: 10.68668 val_loss: 3.45957\n",
      "Epoch 8/50 train_loss: 9.68065 val_loss: 3.13362\n",
      "Epoch 9/50 train_loss: 8.84578 val_loss: 2.89913\n",
      "Epoch 10/50 train_loss: 8.13552 val_loss: 2.68247\n",
      "Epoch 11/50 train_loss: 7.54932 val_loss: 2.51185\n",
      "Epoch 12/50 train_loss: 7.07329 val_loss: 2.34389\n",
      "Epoch 13/50 train_loss: 6.64053 val_loss: 2.21628\n",
      "Epoch 14/50 train_loss: 6.28212 val_loss: 2.09421\n",
      "Epoch 15/50 train_loss: 5.96543 val_loss: 2.00667\n",
      "Epoch 16/50 train_loss: 5.70388 val_loss: 1.90626\n",
      "Epoch 17/50 train_loss: 5.45140 val_loss: 1.84769\n",
      "Epoch 18/50 train_loss: 5.26295 val_loss: 1.77690\n",
      "Epoch 19/50 train_loss: 5.07811 val_loss: 1.72975\n",
      "Epoch 20/50 train_loss: 4.93160 val_loss: 1.69271\n",
      "Epoch 21/50 train_loss: 4.82908 val_loss: 1.65816\n",
      "Epoch 22/50 train_loss: 4.71118 val_loss: 1.63283\n",
      "Epoch 23/50 train_loss: 4.62138 val_loss: 1.59810\n",
      "Epoch 24/50 train_loss: 4.53703 val_loss: 1.56777\n",
      "Epoch 25/50 train_loss: 4.47314 val_loss: 1.56302\n",
      "Epoch 26/50 train_loss: 4.40920 val_loss: 1.52636\n",
      "Epoch 27/50 train_loss: 4.33216 val_loss: 1.49759\n",
      "Epoch 28/50 train_loss: 4.28115 val_loss: 1.48877\n",
      "Epoch 29/50 train_loss: 4.23062 val_loss: 1.47091\n",
      "Epoch 30/50 train_loss: 4.18266 val_loss: 1.46184\n",
      "Epoch 31/50 train_loss: 4.12815 val_loss: 1.44843\n",
      "Epoch 32/50 train_loss: 4.07753 val_loss: 1.42819\n",
      "Epoch 33/50 train_loss: 4.03124 val_loss: 1.40498\n",
      "Epoch 34/50 train_loss: 3.98680 val_loss: 1.38478\n",
      "Epoch 35/50 train_loss: 3.93525 val_loss: 1.37795\n",
      "Epoch 36/50 train_loss: 3.91029 val_loss: 1.35606\n",
      "Epoch 37/50 train_loss: 3.87382 val_loss: 1.35243\n",
      "Epoch 38/50 train_loss: 3.83697 val_loss: 1.35024\n",
      "Epoch 39/50 train_loss: 3.79077 val_loss: 1.33229\n",
      "Epoch 40/50 train_loss: 3.75898 val_loss: 1.33274\n",
      "Epoch 41/50 train_loss: 3.73415 val_loss: 1.32381\n",
      "Epoch 42/50 train_loss: 3.71141 val_loss: 1.30490\n",
      "Epoch 43/50 train_loss: 3.67958 val_loss: 1.29111\n",
      "Epoch 44/50 train_loss: 3.65287 val_loss: 1.29823\n",
      "Epoch 45/50 train_loss: 3.62366 val_loss: 1.29145\n",
      "Epoch 46/50 train_loss: 3.60569 val_loss: 1.28099\n",
      "Epoch 47/50 train_loss: 3.58326 val_loss: 1.26653\n",
      "Epoch 48/50 train_loss: 3.56376 val_loss: 1.26218\n",
      "Epoch 49/50 train_loss: 3.54784 val_loss: 1.25980\n",
      "Epoch 50/50 train_loss: 3.52387 val_loss: 1.25506\n",
      "Best model saved at split 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory .save_model does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 25\u001b[0m\n\u001b[1;32m      1\u001b[0m model_choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph Cross Attention\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      4\u001b[0m     training_data,\n\u001b[1;32m      5\u001b[0m     geneVocab,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     beta\u001b[38;5;241m=\u001b[39mbeta,\n\u001b[1;32m     23\u001b[0m     )\n\u001b[0;32m---> 25\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/DATA/User/wuxinchao/project/spatial-CITE-seq/sc_st_attention_integration/GSPI/train.py:393\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# save the best model parameters\u001b[39;00m\n\u001b[1;32m    389\u001b[0m save_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_model\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m    392\u001b[0m }\n\u001b[0;32m--> 393\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.save_model/best_model.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_history_for_splits, val_history_for_splits\n",
      "File \u001b[0;32m~/software/miniconda3/envs/pytorch-gpu/lib/python3.9/site-packages/torch/serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/software/miniconda3/envs/pytorch-gpu/lib/python3.9/site-packages/torch/serialization.py:315\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/software/miniconda3/envs/pytorch-gpu/lib/python3.9/site-packages/torch/serialization.py:288\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory .save_model does not exist."
     ]
    }
   ],
   "source": [
    "model_choice = \"Graph Cross Attention\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    training_data,\n",
    "    model_choice=model_choice, \n",
    "    rna_input_dim=rna_input_dim, \n",
    "    prot_input_dim=prot_input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    embedding_dim=embedding_dim,\n",
    "    heads=heads,\n",
    "    num_blocks=num_blocks, \n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    epochs=epochs,\n",
    "    mask_ratio=mask_ratio,\n",
    "    permute=permute,\n",
    "    preserve_rate=preserve_rate,\n",
    "    num_splits=num_splits,\n",
    "    device=device,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    )\n",
    "\n",
    "train_losses, val_losses = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model parameters\n",
    "save_dict = {\n",
    "    \"model\": trainer.best_model.state_dict(),\n",
    "    \"optimizer\": trainer.optimizer.state_dict(),\n",
    "}\n",
    "torch.save(save_dict, \"../save_model/best_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/wuxinchao/data/st_cite_data/\"\n",
    "prot_data_path = \"B01825A4_protein_filter.csv\"\n",
    "rna_data_path = \"B01825A4_rna_raw.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import construct_spatial_adata\n",
    "\n",
    "sp_mudata = construct_spatial_adata(\n",
    "    data_path, \n",
    "    rna_data=rna_data_path, \n",
    "    prot_data=prot_data_path\n",
    ")\n",
    "sp_mudata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_adata = sp_mudata.mod[\"rna\"]\n",
    "prot_adata = sp_mudata.mod[\"prot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuxinchao/software/miniconda3/envs/pytorch-gpu/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:197: UserWarning: Some cells have zero counts\n",
      "  warn(UserWarning('Some cells have zero counts'))\n",
      "/home/wuxinchao/software/miniconda3/envs/pytorch-gpu/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py:62: UserWarning: `flavor='seurat_v3'` expects raw count data, but non-integers were found.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sc.pp.normalize_total(rna_adata)\n",
    "sc.pp.log1p(rna_adata)\n",
    "rna_adata.obs_names_make_unique()\n",
    "rna_adata.var['mt'] = rna_adata.var_names.str.startswith('MT-')\n",
    "rna_adata.layers[\"counts\"] = rna_adata.X.copy()\n",
    "sc.pp.highly_variable_genes(\n",
    "    rna_adata,\n",
    "    n_top_genes=2000,\n",
    "    flavor=\"seurat_v3\",\n",
    "    layer=\"counts\",\n",
    ")\n",
    "\n",
    "sc.pp.scale(rna_adata, max_value=10)\n",
    "sc.tl.pca(rna_adata, svd_solver=\"arpack\")\n",
    "# sc.pl.pca_variance_ratio(rna_adata, log=True)\n",
    "sc.pp.neighbors(rna_adata, n_pcs=50)\n",
    "sc.tl.umap(rna_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from muon import prot as pt\n",
    "\n",
    "pt.pp.clr(prot_adata)\n",
    "sp_mudata.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_mudata.write_h5mu(data_path + \"sp_mudata.h5mu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>MuData object with n_obs × n_vars = 8628 × 25828\n",
       "  obsm:\t&#x27;spatial&#x27;\n",
       "  2 modalities\n",
       "    rna:\t8628 x 25818\n",
       "      var:\t&#x27;mt&#x27;, &#x27;highly_variable&#x27;, &#x27;highly_variable_rank&#x27;, &#x27;means&#x27;, &#x27;variances&#x27;, &#x27;variances_norm&#x27;, &#x27;mean&#x27;, &#x27;std&#x27;\n",
       "      uns:\t&#x27;hvg&#x27;, &#x27;log1p&#x27;, &#x27;neighbors&#x27;, &#x27;pca&#x27;, &#x27;umap&#x27;\n",
       "      obsm:\t&#x27;X_pca&#x27;, &#x27;X_umap&#x27;, &#x27;spatial&#x27;\n",
       "      varm:\t&#x27;PCs&#x27;\n",
       "      layers:\t&#x27;counts&#x27;\n",
       "      obsp:\t&#x27;connectivities&#x27;, &#x27;distances&#x27;\n",
       "    prot:\t8628 x 10\n",
       "      obsm:\t&#x27;spatial&#x27;</pre>"
      ],
      "text/plain": [
       "MuData object with n_obs × n_vars = 8628 × 25828\n",
       "  obsm:\t'spatial'\n",
       "  2 modalities\n",
       "    rna:\t8628 x 25818\n",
       "      var:\t'mt', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'mean', 'std'\n",
       "      uns:\t'hvg', 'log1p', 'neighbors', 'pca', 'umap'\n",
       "      obsm:\t'X_pca', 'X_umap', 'spatial'\n",
       "      varm:\t'PCs'\n",
       "      layers:\t'counts'\n",
       "      obsp:\t'connectivities', 'distances'\n",
       "    prot:\t8628 x 10\n",
       "      obsm:\t'spatial'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "sp_mudata = mu.read_h5mu(data_path + \"sp_mudata.h5mu\")\n",
    "rna_adata = sp_mudata.mod[\"rna\"]\n",
    "prot_adata = sp_mudata.mod[\"prot\"]\n",
    "sp_mudata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneVocab.update_gene_dict(rna_adata)\n",
    "proteinVocab.update_gene_dict(prot_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1439555/1871230178.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  edge_index = torch.tensor(edge_index,\n"
     ]
    }
   ],
   "source": [
    "concat_data = np.concatenate(\n",
    "    [rna_adata.X, prot_adata.X], axis=1\n",
    ")\n",
    "\n",
    "concat_spatial_encoding_data = np.concatenate(\n",
    "    [rna_adata.X, prot_adata.X, sp_mudata.obsm[\"spatial\"]], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "adj_mtx = rna_adata.obsp['connectivities'].toarray()\n",
    "edge_index = adj_mtx.nonzero()\n",
    "edge_index = torch.tensor(edge_index, \n",
    "        dtype=torch.long).contiguous()\n",
    "\n",
    "scCITEseq_data = Data(x=torch.tensor(\n",
    "    concat_data, dtype=torch.float), \n",
    "    edge_index=edge_index)\n",
    "\n",
    "spCITEseq_data = Data(x=torch.tensor(\n",
    "    concat_spatial_encoding_data, dtype=torch.float), \n",
    "    edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 2\n",
    "num_val = 0.2\n",
    "num_test = 0.2\n",
    "\n",
    "tsf = RandomNodeSplit(num_splits=num_splits, \n",
    "                      num_val=num_val, \n",
    "                      num_test=num_test, \n",
    "                      key=None\n",
    "                      )\n",
    "training_data = tsf(scCITEseq_data)\n",
    "spatial_training_data = tsf(spCITEseq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting for the model\n",
    "rna_input_dim = rna_adata.shape[1]\n",
    "prot_input_dim = prot_adata.shape[1]\n",
    "hidden_dim = 32\n",
    "embedding_dim = 32\n",
    "heads = 4\n",
    "num_blocks = 2\n",
    "permute = True\n",
    "preserve_rate = 0.2\n",
    "alpha = 0.4\n",
    "beta = 0.4\n",
    "\n",
    "# setting for the trainer\n",
    "batch_size = 256\n",
    "lr = 1e-6\n",
    "epochs = 100\n",
    "mask_ratio = 0.85\n",
    "num_splits = 2\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune with spatial cite-seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align features of fine-tuning data to the pre-trained model\n",
    "geneVocab.align_features(rna_adata)\n",
    "proteinVocab.align_features(prot_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 train_loss: nan val_loss: nan\n",
      "Epoch 2/25 train_loss: nan val_loss: nan\n",
      "Epoch 3/25 train_loss: nan val_loss: nan\n",
      "Epoch 4/25 train_loss: nan val_loss: nan\n",
      "Epoch 5/25 train_loss: nan val_loss: nan\n",
      "Epoch 6/25 train_loss: nan val_loss: nan\n",
      "Epoch 7/25 train_loss: nan val_loss: nan\n",
      "Epoch 8/25 train_loss: nan val_loss: nan\n",
      "Epoch 9/25 train_loss: nan val_loss: nan\n",
      "Epoch 10/25 train_loss: nan val_loss: nan\n",
      "Epoch 11/25 train_loss: nan val_loss: nan\n",
      "Epoch 12/25 train_loss: nan val_loss: nan\n",
      "Epoch 13/25 train_loss: nan val_loss: nan\n",
      "Epoch 14/25 train_loss: nan val_loss: nan\n",
      "Epoch 15/25 train_loss: nan val_loss: nan\n",
      "Epoch 16/25 train_loss: nan val_loss: nan\n",
      "Epoch 17/25 train_loss: nan val_loss: nan\n",
      "Epoch 18/25 train_loss: nan val_loss: nan\n",
      "Epoch 19/25 train_loss: nan val_loss: nan\n",
      "Epoch 20/25 train_loss: nan val_loss: nan\n",
      "Epoch 21/25 train_loss: nan val_loss: nan\n",
      "Epoch 22/25 train_loss: nan val_loss: nan\n",
      "Epoch 23/25 train_loss: nan val_loss: nan\n",
      "Epoch 24/25 train_loss: nan val_loss: nan\n",
      "Epoch 25/25 train_loss: nan val_loss: nan\n",
      "Epoch 1/25 train_loss: nan val_loss: nan\n",
      "Epoch 2/25 train_loss: nan val_loss: nan\n",
      "Epoch 3/25 train_loss: nan val_loss: nan\n",
      "Epoch 4/25 train_loss: nan val_loss: nan\n",
      "Epoch 5/25 train_loss: nan val_loss: nan\n",
      "Epoch 6/25 train_loss: nan val_loss: nan\n",
      "Epoch 7/25 train_loss: nan val_loss: nan\n",
      "Epoch 8/25 train_loss: nan val_loss: nan\n",
      "Epoch 9/25 train_loss: nan val_loss: nan\n",
      "Epoch 10/25 train_loss: nan val_loss: nan\n",
      "Epoch 11/25 train_loss: nan val_loss: nan\n",
      "Epoch 12/25 train_loss: nan val_loss: nan\n",
      "Epoch 13/25 train_loss: nan val_loss: nan\n",
      "Epoch 14/25 train_loss: nan val_loss: nan\n",
      "Epoch 15/25 train_loss: nan val_loss: nan\n",
      "Epoch 16/25 train_loss: nan val_loss: nan\n",
      "Epoch 17/25 train_loss: nan val_loss: nan\n",
      "Epoch 18/25 train_loss: nan val_loss: nan\n",
      "Epoch 19/25 train_loss: nan val_loss: nan\n",
      "Epoch 20/25 train_loss: nan val_loss: nan\n",
      "Epoch 21/25 train_loss: nan val_loss: nan\n",
      "Epoch 22/25 train_loss: nan val_loss: nan\n",
      "Epoch 23/25 train_loss: nan val_loss: nan\n",
      "Epoch 24/25 train_loss: nan val_loss: nan\n",
      "Epoch 25/25 train_loss: nan val_loss: nan\n",
      "Best model saved at split 0\n"
     ]
    }
   ],
   "source": [
    "model_choice = \"Spatial Graph Cross Attention\"\n",
    "\n",
    "spatial_trainer = Trainer(\n",
    "    spatial_training_data, \n",
    "    geneVocab,\n",
    "    model_choice=model_choice, \n",
    "    rna_input_dim=rna_input_dim, \n",
    "    prot_input_dim=prot_input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    embedding_dim=embedding_dim,\n",
    "    heads=heads,\n",
    "    num_blocks=num_blocks, \n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    epochs=epochs,\n",
    "    mask_ratio=mask_ratio,\n",
    "    permute=permute,\n",
    "    preserve_rate=preserve_rate,\n",
    "    num_splits=num_splits,\n",
    "    device=device,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    )\n",
    "\n",
    "spatial_train_losses, spatial_val_losses = spatial_trainer.fine_tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
